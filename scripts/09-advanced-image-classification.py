import gradio as gr
import torch
import torchvision.transforms as transforms
from PIL import Image
import json
import time
import numpy as np

class ImageClassificationPipeline:
    """é«˜çº§å›¾åƒåˆ†ç±»ç®¡é“"""
    
    def __init__(self):
        self.models = {}
        self.labels = {}
        self.load_models()
    
    def load_models(self):
        """åŠ è½½å¤šä¸ªé¢„è®­ç»ƒæ¨¡å‹"""
        print("ğŸ”„ æ­£åœ¨åŠ è½½å¤šä¸ªå›¾åƒåˆ†ç±»æ¨¡å‹...")
        
        try:
            # ResNet-18
            self.models['resnet18'] = torch.hub.load('pytorch/vision:v0.10.0', 'resnet18', pretrained=True).eval()
            print("âœ… ResNet-18 åŠ è½½å®Œæˆ")
            
            # ResNet-50
            self.models['resnet50'] = torch.hub.load('pytorch/vision:v0.10.0', 'resnet50', pretrained=True).eval()
            print("âœ… ResNet-50 åŠ è½½å®Œæˆ")
            
            # MobileNet V2
            self.models['mobilenet'] = torch.hub.load('pytorch/vision:v0.10.0', 'mobilenet_v2', pretrained=True).eval()
            print("âœ… MobileNet V2 åŠ è½½å®Œæˆ")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            # åˆ›å»ºè™šæ‹Ÿæ¨¡å‹ç”¨äºæ¼”ç¤º
            self.models['demo'] = None
    
    def get_imagenet_labels(self):
        """è·å– ImageNet æ ‡ç­¾"""
        labels = [
            "çŒ«ç§‘åŠ¨ç‰©", "çŠ¬ç§‘åŠ¨ç‰©", "é¸Ÿç±»", "é±¼ç±»", "çˆ¬è¡ŒåŠ¨ç‰©",
            "å“ºä¹³åŠ¨ç‰©", "æ˜†è™«", "èŠ±æœµ", "æ ‘æœ¨", "å»ºç­‘ç‰©",
            "è½¦è¾†", "é£æœº", "èˆ¹åª", "é£Ÿç‰©", "æ°´æœ",
            "è”¬èœ", "å·¥å…·", "å®¶å…·", "ç”µå­è®¾å¤‡", "è¿åŠ¨å™¨æ"
        ]
        return labels
    
    def preprocess_image(self, image):
        """å›¾åƒé¢„å¤„ç†"""
        if image is None:
            return None
            
        preprocess = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], 
                               std=[0.229, 0.224, 0.225]),
        ])
        
        return preprocess(image).unsqueeze(0)
    
    def predict_with_model(self, image, model_name="resnet18"):
        """ä½¿ç”¨æŒ‡å®šæ¨¡å‹è¿›è¡Œé¢„æµ‹"""
        if image is None:
            return {"é”™è¯¯": "è¯·ä¸Šä¼ å›¾åƒ"}
        
        start_time = time.time()
        
        try:
            # é¢„å¤„ç†å›¾åƒ
            input_tensor = self.preprocess_image(image)
            
            if model_name in self.models and self.models[model_name] is not None:
                model = self.models[model_name]
                
                with torch.no_grad():
                    output = model(input_tensor)
                    probabilities = torch.nn.functional.softmax(output[0], dim=0)
                
                # è·å–å‰5ä¸ªé¢„æµ‹ç»“æœ
                top_prob, top_indices = torch.topk(probabilities, 5)
                
                # ä½¿ç”¨ç®€åŒ–æ ‡ç­¾
                labels = self.get_imagenet_labels()
                
                confidences = {}
                for i in range(len(top_prob)):
                    idx = top_indices[i].item() % len(labels)  # ç¡®ä¿ç´¢å¼•åœ¨èŒƒå›´å†…
                    prob = top_prob[i].item()
                    label = labels[idx]
                    confidences[f"{label} (ç±»åˆ«{idx})"] = prob
                    
            else:
                # æ¼”ç¤ºæ¨¡å¼ - ç”Ÿæˆéšæœºé¢„æµ‹
                labels = self.get_imagenet_labels()
                confidences = {}
                probs = np.random.dirichlet(np.ones(5))  # ç”Ÿæˆ5ä¸ªéšæœºæ¦‚ç‡
                
                for i, prob in enumerate(probs):
                    label = labels[i % len(labels)]
                    confidences[f"{label} (æ¼”ç¤º)"] = float(prob)
            
            inference_time = time.time() - start_time
            
            # æ·»åŠ æ¨ç†æ—¶é—´ä¿¡æ¯
            confidences[f"â±ï¸ æ¨ç†æ—¶é—´: {inference_time:.3f}ç§’"] = 0.0
            
            return confidences
            
        except Exception as e:
            return {"å¤„ç†é”™è¯¯": 1.0, f"é”™è¯¯: {str(e)}": 0.0}
    
    def compare_models(self, image):
        """æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ"""
        if image is None:
            return "è¯·ä¸Šä¼ å›¾åƒè¿›è¡Œæ¯”è¾ƒ"
        
        results = {}
        
        for model_name in ['resnet18', 'resnet50', 'mobilenet']:
            if model_name in self.models:
                prediction = self.predict_with_model(image, model_name)
                # è·å–æœ€é«˜ç½®ä¿¡åº¦çš„é¢„æµ‹
                if prediction and len(prediction) > 1:
                    top_pred = max(prediction.items(), key=lambda x: x[1] if isinstance(x[1], (int, float)) else 0)
                    results[f"{model_name.upper()}"] = f"{top_pred[0]}: {top_pred[1]:.3f}"
        
        if not results:
            return "æ¨¡å‹æ¯”è¾ƒæš‚ä¸å¯ç”¨"
        
        comparison_text = "## ğŸ” æ¨¡å‹æ¯”è¾ƒç»“æœ\n\n"
        for model, result in results.items():
            comparison_text += f"**{model}**: {result}\n\n"
        
        return comparison_text

# åˆå§‹åŒ–åˆ†ç±»ç®¡é“
pipeline = ImageClassificationPipeline()

def create_advanced_demo():
    """åˆ›å»ºé«˜çº§å›¾åƒåˆ†ç±»æ¼”ç¤º"""
    
    with gr.Blocks(theme=gr.themes.Soft(), title="é«˜çº§å›¾åƒåˆ†ç±»") as demo:
        gr.Markdown("""
        # ğŸ¯ é«˜çº§å›¾åƒåˆ†ç±»æ¼”ç¤º
        
        ## åŠŸèƒ½ç‰¹ç‚¹
        - ğŸ¤– å¤šæ¨¡å‹æ”¯æŒ (ResNet-18/50, MobileNet V2)
        - âš¡ å®æ—¶æ¨ç†æ€§èƒ½ç›‘æ§
        - ğŸ“Š æ¨¡å‹æ¯”è¾ƒåˆ†æ
        - ğŸ¨ å¯è§†åŒ–ç»“æœå±•ç¤º
        """)
        
        with gr.Tab("å•æ¨¡å‹åˆ†ç±»"):
            with gr.Row():
                with gr.Column():
                    image_input = gr.Image(type="pil", label="ä¸Šä¼ å›¾åƒ")
                    model_choice = gr.Dropdown(
                        choices=["resnet18", "resnet50", "mobilenet"],
                        value="resnet18",
                        label="é€‰æ‹©æ¨¡å‹"
                    )
                    classify_btn = gr.Button("ğŸ” å¼€å§‹åˆ†ç±»", variant="primary")
                
                with gr.Column():
                    classification_output = gr.Label(
                        num_top_classes=5,
                        label="åˆ†ç±»ç»“æœ"
                    )
        
        with gr.Tab("æ¨¡å‹æ¯”è¾ƒ"):
            with gr.Row():
                with gr.Column():
                    compare_image = gr.Image(type="pil", label="ä¸Šä¼ å›¾åƒè¿›è¡Œæ¯”è¾ƒ")
                    compare_btn = gr.Button("ğŸ†š æ¯”è¾ƒæ¨¡å‹", variant="secondary")
                
                with gr.Column():
                    comparison_output = gr.Markdown(label="æ¯”è¾ƒç»“æœ")
        
        with gr.Tab("æ‰¹é‡å¤„ç†"):
            with gr.Row():
                with gr.Column():
                    batch_images = gr.File(
                        file_count="multiple",
                        file_types=["image"],
                        label="ä¸Šä¼ å¤šå¼ å›¾åƒ"
                    )
                    batch_model = gr.Dropdown(
                        choices=["resnet18", "resnet50", "mobilenet"],
                        value="resnet18",
                        label="æ‰¹å¤„ç†æ¨¡å‹"
                    )
                    batch_btn = gr.Button("ğŸ“¦ æ‰¹é‡å¤„ç†", variant="secondary")
                
                with gr.Column():
                    batch_output = gr.Textbox(
                        label="æ‰¹å¤„ç†ç»“æœ",
                        lines=10,
                        max_lines=20
                    )
        
        # äº‹ä»¶ç»‘å®š
        classify_btn.click(
            fn=lambda img, model: pipeline.predict_with_model(img, model),
            inputs=[image_input, model_choice],
            outputs=classification_output
        )
        
        compare_btn.click(
            fn=pipeline.compare_models,
            inputs=compare_image,
            outputs=comparison_output
        )
        
        def batch_process(files, model_name):
            if not files:
                return "è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶"
            
            results = []
            for i, file in enumerate(files[:5]):  # é™åˆ¶å¤„ç†5å¼ å›¾åƒ
                try:
                    image = Image.open(file.name)
                    prediction = pipeline.predict_with_model(image, model_name)
                    top_pred = max(prediction.items(), key=lambda x: x[1] if isinstance(x[1], (int, float)) else 0)
                    results.append(f"å›¾åƒ {i+1}: {top_pred[0]} ({top_pred[1]:.3f})")
                except Exception as e:
                    results.append(f"å›¾åƒ {i+1}: å¤„ç†å¤±è´¥ - {str(e)}")
            
            return "\n".join(results)
        
        batch_btn.click(
            fn=batch_process,
            inputs=[batch_images, batch_model],
            outputs=batch_output
        )
        
        # ç¤ºä¾‹
        gr.Examples(
            examples=[
                ["https://images.unsplash.com/photo-1574158622682-e40e69881006?w=300&h=300&fit=crop"],
                ["https://images.unsplash.com/photo-1552053831-71594a27632d?w=300&h=300&fit=crop"],
            ],
            inputs=image_input,
            outputs=classification_output,
            fn=lambda img: pipeline.predict_with_model(img, "resnet18"),
            cache_examples=False
        )
    
    return demo

# å¯åŠ¨æ¼”ç¤º
if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨é«˜çº§å›¾åƒåˆ†ç±»æ¼”ç¤º...")
    demo = create_advanced_demo()
    demo.launch(
        server_name="0.0.0.0",
        server_port=7861,
        share=False
    )
